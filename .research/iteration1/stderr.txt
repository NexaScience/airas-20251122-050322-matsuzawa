Downloading cpython-3.11.14-linux-x86_64-gnu (download) (29.1MiB)
 Downloaded cpython-3.11.14-linux-x86_64-gnu (download)
Using CPython 3.11.14
Creating virtual environment at: .venv
Resolved 132 packages in 566ms
Downloading tokenizers (3.1MiB)
Downloading pydantic-core (2.0MiB)
Downloading aiohttp (1.7MiB)
Downloading numpy (16.1MiB)
Downloading fonttools (4.7MiB)
Downloading pillow (6.7MiB)
Downloading hf-xet (3.2MiB)
Downloading networkx (1.9MiB)
Downloading kiwisolver (1.4MiB)
Downloading sqlalchemy (3.2MiB)
Downloading transformers (11.4MiB)
Downloading nvidia-cuda-cupti-cu12 (9.8MiB)
Downloading triton (162.5MiB)
Downloading nvidia-cusparse-cu12 (274.9MiB)
Downloading nvidia-curand-cu12 (60.7MiB)
Downloading pyarrow (45.5MiB)
Downloading nvidia-cublas-cu12 (566.8MiB)
Downloading nvidia-nvjitlink-cu12 (37.4MiB)
Downloading nvidia-cufile-cu12 (1.1MiB)
Downloading bitsandbytes (56.6MiB)
Downloading nvidia-cufft-cu12 (184.2MiB)
Downloading scikit-learn (9.3MiB)
Downloading nvidia-cusparselt-cu12 (273.9MiB)
Downloading nvidia-cuda-nvrtc-cu12 (84.0MiB)
Downloading scipy (34.2MiB)
Downloading nvidia-cusolver-cu12 (255.1MiB)
Downloading torch (858.1MiB)
Downloading matplotlib (8.3MiB)
Downloading sympy (6.0MiB)
Downloading nvidia-nccl-cu12 (307.4MiB)
Downloading pandas (12.2MiB)
Downloading nvidia-cudnn-cu12 (674.0MiB)
Downloading wandb (19.3MiB)
Downloading nvidia-nvshmem-cu12 (118.9MiB)
 Downloaded nvidia-cufile-cu12
 Downloaded kiwisolver
 Downloaded aiohttp
 Downloaded pydantic-core
 Downloaded tokenizers
 Downloaded sqlalchemy
 Downloaded hf-xet
 Downloaded networkx
 Downloaded fonttools
 Downloaded pillow
 Downloaded sympy
 Downloaded matplotlib
 Downloaded scikit-learn
 Downloaded nvidia-cuda-cupti-cu12
 Downloaded transformers
 Downloaded numpy
 Downloaded wandb
 Downloaded pandas
 Downloaded nvidia-nvjitlink-cu12
 Downloaded scipy
 Downloaded bitsandbytes
 Downloaded pyarrow
 Downloaded nvidia-curand-cu12
 Downloaded nvidia-cuda-nvrtc-cu12
 Downloaded nvidia-nvshmem-cu12
 Downloaded triton
 Downloaded nvidia-cufft-cu12
 Downloaded nvidia-cusolver-cu12
 Downloaded nvidia-cusparse-cu12
 Downloaded nvidia-cusparselt-cu12
 Downloaded nvidia-nccl-cu12
 Downloaded nvidia-cublas-cu12
 Downloaded nvidia-cudnn-cu12
 Downloaded torch
Prepared 100 packages in 33.70s
Installed 100 packages in 320ms
 + accelerate==1.12.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.2
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + bitsandbytes==0.48.2
 + certifi==2025.11.12
 + charset-normalizer==3.4.4
 + click==8.3.1
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.5
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.6.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.18.0
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.1
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.7.0
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.45.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.1
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.1
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.23.0
 + xxhash==3.6.0
 + yarl==1.22.0
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/src/main.py:13: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/src/train.py:199: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 226322.15 examples/s]
Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 464937.14 examples/s]
Map:   0%|          | 0/7099 [00:00<?, ? examples/s]Map:   4%|▍         | 290/7099 [00:00<00:02, 2874.73 examples/s]Map:   8%|▊         | 594/7099 [00:00<00:02, 2960.97 examples/s]Map:  13%|█▎        | 897/7099 [00:00<00:02, 2990.74 examples/s]Map:  18%|█▊        | 1305/7099 [00:00<00:02, 2792.64 examples/s]Map:  23%|██▎       | 1615/7099 [00:00<00:01, 2886.00 examples/s]Map:  28%|██▊       | 1998/7099 [00:00<00:02, 1755.70 examples/s]Map:  32%|███▏      | 2239/7099 [00:01<00:02, 1883.35 examples/s]Map:  36%|███▌      | 2546/7099 [00:01<00:02, 2141.10 examples/s]Map:  40%|████      | 2854/7099 [00:01<00:01, 2362.87 examples/s]Map:  44%|████▍     | 3156/7099 [00:01<00:01, 2423.70 examples/s]Map:  49%|████▉     | 3462/7099 [00:01<00:01, 2583.99 examples/s]Map:  53%|█████▎    | 3774/7099 [00:01<00:01, 2724.73 examples/s]Map:  59%|█████▉    | 4177/7099 [00:01<00:01, 2705.90 examples/s]Map:  63%|██████▎   | 4482/7099 [00:01<00:00, 2791.99 examples/s]Map:  68%|██████▊   | 4795/7099 [00:01<00:00, 2881.05 examples/s]Map:  73%|███████▎  | 5189/7099 [00:02<00:00, 2784.10 examples/s]Map:  77%|███████▋  | 5501/7099 [00:02<00:00, 2869.66 examples/s]Map:  82%|████████▏ | 5811/7099 [00:02<00:00, 2930.31 examples/s]Map:  87%|████████▋ | 6210/7099 [00:02<00:00, 2829.02 examples/s]Map:  92%|█████████▏| 6518/7099 [00:02<00:00, 2892.58 examples/s]Map:  96%|█████████▋| 6833/7099 [00:02<00:00, 2957.98 examples/s]Map: 100%|██████████| 7099/7099 [00:02<00:00, 2625.55 examples/s]
Map:   0%|          | 0/374 [00:00<?, ? examples/s]Map: 100%|██████████| 374/374 [00:00<00:00, 3660.59 examples/s]Map: 100%|██████████| 374/374 [00:00<00:00, 3615.12 examples/s]
Map:   0%|          | 0/1319 [00:00<?, ? examples/s]Map:  34%|███▍      | 455/1319 [00:00<00:00, 4524.28 examples/s]Map:  70%|██████▉   | 921/1319 [00:00<00:00, 4600.01 examples/s]Map: 100%|██████████| 1319/1319 [00:00<00:00, 4253.19 examples/s]
Epoch 0:   0%|          | 0/7099 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Epoch 0:   0%|          | 0/7099 [00:01<?, ?it/s, loss=17.5453]Epoch 0:   0%|          | 1/7099 [00:01<3:02:06,  1.54s/it, loss=17.5453]Epoch 0:   0%|          | 1/7099 [00:02<3:02:06,  1.54s/it, loss=17.2137]Epoch 0:   0%|          | 2/7099 [00:02<2:47:56,  1.42s/it, loss=17.2137]Epoch 0:   0%|          | 2/7099 [00:02<2:50:07,  1.44s/it, loss=17.2137]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Downloading cpython-3.11.14-linux-x86_64-gnu (download) (29.1MiB)
 Downloaded cpython-3.11.14-linux-x86_64-gnu (download)
Using CPython 3.11.14
Creating virtual environment at: .venv
Resolved 132 packages in 396ms
Downloading nvidia-cuda-nvrtc-cu12 (84.0MiB)
Downloading nvidia-cufile-cu12 (1.1MiB)
Downloading nvidia-curand-cu12 (60.7MiB)
Downloading aiohttp (1.7MiB)
Downloading pandas (12.2MiB)
Downloading pillow (6.7MiB)
Downloading tokenizers (3.1MiB)
Downloading nvidia-cuda-cupti-cu12 (9.8MiB)
Downloading nvidia-cublas-cu12 (566.8MiB)
Downloading nvidia-cusparse-cu12 (274.9MiB)
Downloading kiwisolver (1.4MiB)
Downloading scikit-learn (9.3MiB)
Downloading sympy (6.0MiB)
Downloading nvidia-nvjitlink-cu12 (37.4MiB)
Downloading hf-xet (3.2MiB)
Downloading wandb (19.3MiB)
Downloading nvidia-nccl-cu12 (307.4MiB)
Downloading networkx (1.9MiB)
Downloading matplotlib (8.3MiB)
Downloading pydantic-core (2.0MiB)
Downloading triton (162.5MiB)
Downloading scipy (34.2MiB)
Downloading nvidia-cufft-cu12 (184.2MiB)
Downloading nvidia-cudnn-cu12 (674.0MiB)
Downloading torch (858.1MiB)
Downloading bitsandbytes (56.6MiB)
Downloading transformers (11.4MiB)
Downloading nvidia-cusparselt-cu12 (273.9MiB)
Downloading sqlalchemy (3.2MiB)
Downloading pyarrow (45.5MiB)
Downloading nvidia-cusolver-cu12 (255.1MiB)
Downloading nvidia-nvshmem-cu12 (118.9MiB)
Downloading numpy (16.1MiB)
Downloading fonttools (4.7MiB)
 Downloaded nvidia-cufile-cu12
 Downloaded kiwisolver
 Downloaded aiohttp
 Downloaded pydantic-core
 Downloaded tokenizers
 Downloaded sqlalchemy
 Downloaded hf-xet
 Downloaded networkx
 Downloaded fonttools
 Downloaded pillow
 Downloaded sympy
 Downloaded matplotlib
 Downloaded scikit-learn
 Downloaded nvidia-cuda-cupti-cu12
 Downloaded transformers
 Downloaded numpy
 Downloaded wandb
 Downloaded pandas
 Downloaded nvidia-nvjitlink-cu12
 Downloaded scipy
 Downloaded bitsandbytes
 Downloaded nvidia-curand-cu12
 Downloaded nvidia-cuda-nvrtc-cu12
 Downloaded pyarrow
 Downloaded nvidia-nvshmem-cu12
 Downloaded triton
 Downloaded nvidia-cufft-cu12
 Downloaded nvidia-cusolver-cu12
 Downloaded nvidia-cusparse-cu12
 Downloaded nvidia-cusparselt-cu12
 Downloaded nvidia-nccl-cu12
 Downloaded nvidia-cublas-cu12
 Downloaded nvidia-cudnn-cu12
 Downloaded torch
Prepared 100 packages in 32.77s
Installed 100 packages in 325ms
 + accelerate==1.12.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.2
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + bitsandbytes==0.48.2
 + certifi==2025.11.12
 + charset-normalizer==3.4.4
 + click==8.3.1
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.5
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.6.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.18.0
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.1
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.7.0
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.45.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.1
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.1
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.23.0
 + xxhash==3.6.0
 + yarl==1.22.0
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/src/main.py:13: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/src/train.py:199: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/runner/work/airas-20251122-050322-matsuzawa/airas-20251122-050322-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 246496.75 examples/s]
Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 416493.79 examples/s]
Map:   0%|          | 0/7099 [00:00<?, ? examples/s]Map:   4%|▍         | 291/7099 [00:00<00:02, 2885.68 examples/s]Map:   8%|▊         | 592/7099 [00:00<00:02, 2953.61 examples/s]Map:  13%|█▎        | 893/7099 [00:00<00:02, 2976.93 examples/s]Map:  18%|█▊        | 1311/7099 [00:00<00:02, 2798.31 examples/s]Map:  24%|██▍       | 1739/7099 [00:00<00:01, 2816.67 examples/s]Map:  29%|██▉       | 2083/7099 [00:00<00:02, 1699.06 examples/s]Map:  34%|███▎      | 2388/7099 [00:01<00:02, 1945.88 examples/s]Map:  38%|███▊      | 2694/7099 [00:01<00:02, 2176.46 examples/s]Map:  42%|████▏     | 3000/7099 [00:01<00:01, 2279.05 examples/s]Map:  47%|████▋     | 3304/7099 [00:01<00:01, 2458.68 examples/s]Map:  51%|█████     | 3609/7099 [00:01<00:01, 2607.80 examples/s]Map:  55%|█████▌    | 3919/7099 [00:01<00:01, 2737.99 examples/s]Map:  61%|██████    | 4323/7099 [00:01<00:01, 2718.02 examples/s]Map:  65%|██████▌   | 4637/7099 [00:01<00:00, 2824.39 examples/s]Map:  70%|██████▉   | 4945/7099 [00:01<00:00, 2888.88 examples/s]Map:  75%|███████▌  | 5346/7099 [00:02<00:00, 2806.93 examples/s]Map:  80%|███████▉  | 5662/7099 [00:02<00:00, 2895.08 examples/s]Map:  84%|████████▍ | 5966/7099 [00:02<00:00, 2930.96 examples/s]Map:  90%|████████▉ | 6369/7099 [00:02<00:00, 2839.46 examples/s]Map:  94%|█████████▍| 6678/7099 [00:02<00:00, 2901.59 examples/s]Map:  98%|█████████▊| 6991/7099 [00:02<00:00, 2959.13 examples/s]Map: 100%|██████████| 7099/7099 [00:02<00:00, 2611.86 examples/s]
Map:   0%|          | 0/374 [00:00<?, ? examples/s]Map: 100%|██████████| 374/374 [00:00<00:00, 3692.99 examples/s]Map: 100%|██████████| 374/374 [00:00<00:00, 3647.82 examples/s]
Map:   0%|          | 0/1319 [00:00<?, ? examples/s]Map:  35%|███▍      | 456/1319 [00:00<00:00, 4519.93 examples/s]Map:  70%|███████   | 929/1319 [00:00<00:00, 4637.49 examples/s]Map: 100%|██████████| 1319/1319 [00:00<00:00, 4304.77 examples/s]
Epoch 0:   0%|          | 0/7099 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Epoch 0:   0%|          | 0/7099 [00:01<?, ?it/s, loss=17.5453]Epoch 0:   0%|          | 1/7099 [00:01<3:02:28,  1.54s/it, loss=17.5453]Epoch 0:   0%|          | 1/7099 [00:02<3:02:28,  1.54s/it, loss=17.2137]Epoch 0:   0%|          | 2/7099 [00:02<2:47:29,  1.42s/it, loss=17.2137]Epoch 0:   0%|          | 2/7099 [00:02<2:49:47,  1.44s/it, loss=17.2137]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
